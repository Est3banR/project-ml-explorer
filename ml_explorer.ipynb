{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZXUiJAacFRT"
      },
      "source": [
        "# 1. Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQw57BLb3dFh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "import joblib\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from prettytable import PrettyTable\n",
        "from datetime import datetime\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.cluster.hierarchy import fcluster, linkage\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from umap import UMAP\n",
        "from sklearn.ensemble import (\n",
        "    AdaBoostClassifier,\n",
        "    GradientBoostingRegressor,\n",
        "    RandomForestClassifier,\n",
        "    RandomForestRegressor,\n",
        ")\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    r2_score,\n",
        "    silhouette_score,\n",
        "    calinski_harabasz_score,\n",
        "    davies_bouldin_score\n",
        ") # all metrics used in the notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScX-De7IdB7L"
      },
      "source": [
        "# 2. Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIssRCV8cKBa"
      },
      "outputs": [],
      "source": [
        "class EDA:\n",
        "    \"\"\"\n",
        "    Class dedicated to load, transform and visualize data.\n",
        "    \"\"\"\n",
        "    def __init__(self, file=None):\n",
        "        \"\"\"\n",
        "        Starts the class and loads the data from a CSV file\n",
        "\n",
        "        Parameters:\n",
        "        -file (str): Path to a CSV file\n",
        "        \"\"\"\n",
        "        if file:\n",
        "            self.df = pd.read_csv(file)\n",
        "        else:\n",
        "            raise ValueError(\"‚ö†Ô∏è No file path provided.\")\n",
        "\n",
        "    \n",
        "    def head_df(self, n=5):\n",
        "        \"\"\"\n",
        "        Returns the first n rows of the DataFrame\n",
        "        \"\"\"\n",
        "        if self.df.empty:\n",
        "            return \"‚ö†Ô∏è No data available\"\n",
        "        else:\n",
        "            return self.df.head(n)\n",
        "\n",
        "    def tail_df(self, n=5):\n",
        "        \"\"\"\n",
        "        Returns the last n rows of the DataFrame\n",
        "        \"\"\"\n",
        "        if self.df.empty:\n",
        "            return \"‚ö†Ô∏è No data available\"\n",
        "        else:\n",
        "            return self.df.tail(n)\n",
        "\n",
        "    def check_data_types(self):\n",
        "        \"\"\"\n",
        "        Shows the data types of each column in the DataFrame\n",
        "        \"\"\"\n",
        "        return self.df.dtypes\n",
        "\n",
        "    def drop_irrelevant_columns(self, columns):\n",
        "        \"\"\"\n",
        "        Drops irrelevant columns from the DataFrame selected by the user\n",
        "\n",
        "        Parameters:\n",
        "        -columns (list): List of column names to drop.\n",
        "        \"\"\"\n",
        "        self.df.drop(columns=columns, inplace=True)\n",
        "\n",
        "    def drop_missing_values(self):\n",
        "        \"\"\"\n",
        "        Drops rows with missing values from the DataFrame\n",
        "        \"\"\"\n",
        "        self.df.dropna(inplace=True)\n",
        "\n",
        "    def detect_outliers(self):\n",
        "        \"\"\"\n",
        "        Extracts the outliers from the DataFrame using the IQR method\n",
        "        (Interquartile Rang)\n",
        "        Parameters:\n",
        "        -df (pd.DataFrame): DataFrame to analyze\n",
        "        Returns:\n",
        "        -Dicc_outliers (dict): Dictionary with the number of outliers for each column\n",
        "        \"\"\"\n",
        "        num_df = self.df.select_dtypes(include=['float64', 'int64'])\n",
        "        if num_df.empty:\n",
        "            return \"No numeric columns to detect outliers.\"\n",
        "\n",
        "        Q1 = num_df.quantile(0.25)\n",
        "        Q3 = num_df.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        outliers = ((num_df < (Q1 - 1.5 * IQR)) | (num_df > (Q3 + 1.5 * IQR))).sum()\n",
        "        Dicc_outliers = {col: outliers[col] for col in num_df.columns if outliers[col] > 0}\n",
        "\n",
        "        return Dicc_outliers if Dicc_outliers else \"No outliers detected\"\n",
        "\n",
        "    def plot_scatter(self, col1, col2):\n",
        "        \"\"\"\n",
        "        Plots a scatter plot of two columns in the DataFrame\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.scatterplot(x=self.df[col1], y=self.df[col2])\n",
        "        plt.title(f'Scatter Plot: {col1} vs {col2}')\n",
        "        plt.xlabel(col1)\n",
        "        plt.ylabel(col2)\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_histogram(self, col):\n",
        "        \"\"\"\n",
        "        Plots a histogram of a column in the DataFrame\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.histplot(self.df[col], kde=True)\n",
        "        plt.title(f'Histogram {col}')\n",
        "        plt.xlabel(col)\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_heatmap(self):\n",
        "        \"\"\"\n",
        "        Plots a heatmap of the correlation matrix of the DataFrame in-line\n",
        "        \"\"\"\n",
        "        num_df = self.df.select_dtypes(include=['float64', 'int64'])\n",
        "        if num_df.empty:\n",
        "            return \"There's no numeric columns to plot a heatmap.\"\n",
        "        num_df = num_df.loc[:, num_df.apply(lambda x: np.std(x) > 0.01)]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12,10))\n",
        "        sns.heatmap(num_df.corr(), cmap=\"coolwarm\", annot=True, ax=ax)\n",
        "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "        ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
        "        ax.set_title(\"Heatmap\")\n",
        "        fig.tight_layout()\n",
        "        fig.show()\n",
        "        plt.pause(0.1)\n",
        "        plt.close(fig)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Returns a string representation of the class. In case user needs to print the class\n",
        "        \"\"\"\n",
        "        return f\"üü° EDA - Dataframe shape: {self.df.shape}\"\n",
        "\n",
        "    def get_df(self):\n",
        "        \"\"\"\n",
        "        Provides a safe copy of the dataset for use in machine learning algorithms\n",
        "        \"\"\"\n",
        "        return self.df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Unsupervised Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHJDmyoocftY"
      },
      "outputs": [],
      "source": [
        "class Unsupervised ():\n",
        "    \"\"\"\n",
        "    Class dedicated to unsupervised learning algorithms.\n",
        "    Contains: Methods and metrics.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe_eda):\n",
        "        self.df = dataframe_eda.get_df()\n",
        "\n",
        "    # Tools and metrics\n",
        "\n",
        "    def byebye_object_values(self):\n",
        "        # Delete object values from the dataframe\n",
        "        self.df = self.df.select_dtypes(exclude=['object'])\n",
        "\n",
        "    def calculate_metrics(self, labels):\n",
        "        \"\"\"\n",
        "        Calculates clustering metrics:\n",
        "        - Silhouette: how well samples fit within their cluster\n",
        "        - Calinski-Harabasz: cluster separation and compactness\n",
        "        - Davies-Bouldin: similarity between clusters\n",
        "        \"\"\"\n",
        "        data = self.df.dropna()\n",
        "        data = (data - data.mean()) / data.std()\n",
        "        metrics = {\n",
        "            \"Silhouette Score\": silhouette_score(data, labels),\n",
        "            \"Calinski-Harabasz\": calinski_harabasz_score(data, labels),\n",
        "            \"Davies-Bouldin\": davies_bouldin_score(data, labels)\n",
        "        }\n",
        "        return metrics\n",
        "    \n",
        "    # -----------------Algorithms------------------------\n",
        "    \n",
        "    def kmeans(self, n_clusters, return_estimator=False):\n",
        "        self.byebye_object_values()\n",
        "        data = self.df\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        labels = kmeans.fit_predict(data)\n",
        "        scores = self.calculate_unsupervised_scores(\"K-Means\", labels)\n",
        "        if return_estimator:\n",
        "            return {\"model\": \"K-Means\", \"metrics\": scores, \"estimator\": kmeans}\n",
        "        return scores\n",
        "\n",
        "    def k_medoids(self, n_clusters, metric='euclidean', return_estimator=False):\n",
        "        self.byebye_object_values()\n",
        "        data = self.df\n",
        "        kmedoids = KMedoids(n_clusters=n_clusters, metric=metric, random_state=42)\n",
        "        labels = kmedoids.fit_predict(data)\n",
        "        scores = self.calculate_unsupervised_scores(\"K-Medoids\", labels)\n",
        "        if return_estimator:\n",
        "            return {\"model\": \"K-Medoids\", \"metrics\": scores, \"estimator\": kmedoids}\n",
        "        return scores\n",
        "        \n",
        "    def hac(self, n_clusters, method='ward', return_estimator=False):\n",
        "        self.byebye_object_values()\n",
        "        data = self.df\n",
        "        linkage_matrix = linkage(data, method=method)\n",
        "        labels = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
        "        scores = self.calculate_unsupervised_scores(\"HAC\", labels)\n",
        "        if return_estimator:\n",
        "            return {\"model\": \"HAC\", \"metrics\": scores, \"estimator\": None}\n",
        "        return scores\n",
        "\n",
        "    def umap_reduc(self, n_clusters, n_components=2, n_neighbors=15, return_estimator=False):\n",
        "        self.byebye_object_values()\n",
        "        data = self.df\n",
        "        reducer = UMAP(n_components=n_components, n_neighbors=n_neighbors, random_state=42)\n",
        "        components = reducer.fit_transform(data)\n",
        "        km = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        labels = km.fit_predict(components)\n",
        "        scores = self.calculate_unsupervised_scores(\"UMAP+KMeans\", labels)\n",
        "        if return_estimator:\n",
        "            pipe = Pipeline([(\"umap\", reducer), (\"kmeans\", km)])\n",
        "            return {\"model\": \"UMAP+KMeans\", \"metrics\": scores, \"estimator\": pipe}\n",
        "        return scores\n",
        "\n",
        "    def calculate_unsupervised_scores(self, model_name, labels):\n",
        "        data = self.df.dropna()\n",
        "        data = (data - data.mean()) / data.std()\n",
        "        silhouette = silhouette_score(data, labels)\n",
        "        calinski = calinski_harabasz_score(data, labels)\n",
        "        davies = davies_bouldin_score(data, labels)\n",
        "        results = {\n",
        "            'model': model_name,\n",
        "            'Silhouette Score': silhouette,\n",
        "            'Calinski-Harabasz': calinski,\n",
        "            'Davies-Bouldin': davies\n",
        "        }\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Supervised Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grQ-5IXLjR-7"
      },
      "outputs": [],
      "source": [
        "class Supervised():\n",
        "    \"\"\"\n",
        "    Class dedicated to supervised learning algorithms.\n",
        "    Contains: Split data, methods and metrics for regression and classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe_eda):\n",
        "        self.df = dataframe_eda.get_df()\n",
        "\n",
        "#-----------------Split Process----------------------------\n",
        "\n",
        "    def get_percent_data_split(self):\n",
        "        \"\"\"\n",
        "        Requests the user to input a percentage for splitting the dataset into training and testing sets.\n",
        "\n",
        "        Returns:\n",
        "        - float: Percentage of data to be used for training (between 0 and 1).\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            try:\n",
        "                df_percentage = float(input(\"Enter the percentage to be used for training (Example: 80) \\n\"))\n",
        "                if 0 < df_percentage < 100:\n",
        "                    return df_percentage / 100\n",
        "                else:\n",
        "                    print(\"Percentage must be between 1 and 99.\")\n",
        "            except ValueError:\n",
        "                print(\"‚ö†Ô∏è Invalid number, please try again...\")\n",
        "\n",
        "    def split_df(self, target_column, test_size=None, random_state=42, task_type=\"classification\"):\n",
        "      \"\"\"\n",
        "      Calls get_percent_data_split and divides the DataFrame into training and testing sets.\n",
        "      Modifies the target column based on the task type (classification or regression).\n",
        "      Shows how many rows are in the training and testing sets.\n",
        "\n",
        "      Parameters:\n",
        "      - target_column: Name of the target column (y).\n",
        "      - test_size: Percentage of the test set. If not provided, it will be calculated automatically.\n",
        "      - random_state: Random seed for reproducibility.\n",
        "\n",
        "      Returns:\n",
        "      -Datasets for modeling X_train, X_test, y_train, y_test\n",
        "      \"\"\"\n",
        "      if test_size is None:\n",
        "          # If test_size is not provided, request the user for the percentage\n",
        "          test_size = 1 - self.get_percent_data_split()\n",
        "\n",
        "      while True:\n",
        "          try:\n",
        "              # Try to split features (X) and target (y)\n",
        "              X = self.df.drop(columns=[target_column])\n",
        "              y = self.df[target_column]\n",
        "              break\n",
        "          except KeyError:\n",
        "              print(f\"Column '{target_column}' does not exist. Please try again.\")\n",
        "              print(\"Available columns:\")\n",
        "              print(self.check_data_types())\n",
        "              target_column = input(\"Enter the target value to be predicted: \")\n",
        "\n",
        "      # Encode the target if it's categorical\n",
        "      X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "      # Process target variable based on task type\n",
        "      if task_type == \"classification\":\n",
        "        if y.dtypes == 'object' or y.dtypes.name == 'category':\n",
        "            from sklearn.preprocessing import LabelEncoder\n",
        "            le = LabelEncoder()\n",
        "            y = le.fit_transform(y)\n",
        "      elif task_type == \"regression\":\n",
        "        # Ensure y is numeric for regression\n",
        "        if not pd.api.types.is_numeric_dtype(y):\n",
        "            try:\n",
        "                y = pd.to_numeric(y, errors=\"raise\")\n",
        "            except Exception as e:\n",
        "                raise ValueError(\n",
        "                    \"Target column is not numeric and cannot be converted: \"\n",
        "                    f\"{e}\"\n",
        "                )\n",
        "      else:\n",
        "          raise ValueError(\"task_type must be 'classification' or 'regression'\")\n",
        "\n",
        "      # Split the data using train_test_split\n",
        "      X_train, X_test, y_train, y_test = train_test_split(\n",
        "          X, y, test_size=test_size, random_state=random_state\n",
        "      )\n",
        "\n",
        "      # Show how many rows are in the training and testing sets\n",
        "      print(f\"Dataset divided:\\n- Training: {X_train.shape[0]} rows \\n- Testing: {X_test.shape[0]} rows\")\n",
        "      return X_train, X_test, y_train, y_test\n",
        "\n",
        "#-----------------Metric Evaluation Process----------------------------\n",
        "    def calculate_regression_scores(self, model_name, y_test, model_predictions):\n",
        "      \"\"\"\n",
        "      Calculates the evaluation metrics for regression models and stores the results in a dictionary.\n",
        "\n",
        "      Parameters:\n",
        "      - model_name: Name of the model\n",
        "      - X_test: Features from the test set.\n",
        "      - y_test: Target Value from the test set.\n",
        "      - model_predictions: Predicted values from the model.\n",
        "\n",
        "      Returns:\n",
        "      - results: Dictionary with evaluation scores\n",
        "      \"\"\"\n",
        "      mse = mean_squared_error(y_test, model_predictions)\n",
        "      r2 = r2_score(y_test, model_predictions)\n",
        "      mae = mean_absolute_error(y_test, model_predictions)\n",
        "      rmse = np.sqrt(mse)\n",
        "      tolerance = 0.1  # Equivalent to 10% tolerance\n",
        "      tolerance_accuracy = np.mean(np.abs(y_test - model_predictions) <= (tolerance * y_test)) * 100\n",
        "\n",
        "      results = {\n",
        "          'model': model_name,\n",
        "          'MSE': mse,\n",
        "          'R2': r2,\n",
        "          'MAE': mae,\n",
        "          'RMSE': rmse,\n",
        "          'tolerance_accuracy': tolerance_accuracy\n",
        "      }\n",
        "      return results\n",
        "\n",
        "    def calculate_classification_scores(self, model_name, y_test, model_predictions):\n",
        "      \"\"\"\n",
        "      Calculates classification evaluation metrics and stores the results in a dictionary.\n",
        "      Metrics were set with average='weighted' to handle imbalanced datasets.\n",
        "      Watermark - Esteban Ramirez M\n",
        "\n",
        "      Parameters:\n",
        "      - model_name: Name of the classification model.\n",
        "      - y_test: Actual target values from the test set.\n",
        "      - model_predictions: Predicted target values generated by the model.\n",
        "\n",
        "      Returns:\n",
        "      - results: Dictionary containing classification evaluation metrics (Accuracy, Precision, Recall, F1-score).\n",
        "      \"\"\"\n",
        "      accuracy = accuracy_score(y_test, model_predictions)\n",
        "      precision = precision_score(y_test, model_predictions, average='weighted')\n",
        "      recall = recall_score(y_test, model_predictions, average='weighted')\n",
        "      f1 = f1_score(y_test, model_predictions, average='weighted')\n",
        "\n",
        "      results = {\n",
        "          'model': model_name,\n",
        "          'accuracy': accuracy,\n",
        "          'precision': precision,\n",
        "          'recall': recall,\n",
        "          'f1_score': f1\n",
        "      }\n",
        "      return results\n",
        "\n",
        "\n",
        "#------------------------Regression Models--------------------------------------------------------------\n",
        "\n",
        "    def regre_lineal_simple(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Runs Simple Linear Regression and calculates multiple performance metrics.\n",
        "      Returns:\n",
        "      - results: Dictionary of regression metrics.\n",
        "      \"\"\"\n",
        "      print(\"Starting Simple Linear Regression...\")\n",
        "      model = LinearRegression()\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      results = self.calculate_regression_scores(\"LinearRegression\", y_test, predictions)\n",
        "      results['estimator'] = model\n",
        "      return results\n",
        "\n",
        "    def regre_regridge(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Runs Ridge Regression and calculates multiple performance metrics.\n",
        "      Returns:\n",
        "      - results: Dictionary of regression metrics.\n",
        "      \"\"\"\n",
        "      print(\"Starting Ridge Regression...\")\n",
        "      model = Ridge(alpha = 1.0)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      results = self.calculate_regression_scores(\"Ridge\", y_test, predictions)\n",
        "      results['estimator'] = model\n",
        "      return results\n",
        "\n",
        "    def regre_decisionTree(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Runs Decision Tree Regressor and calculates multiple performance metrics.\n",
        "      Returns:\n",
        "      - results: Dictionary of regression metrics.\n",
        "      \"\"\"\n",
        "      print(\"Starting Decision Tree Regressor...\")\n",
        "      model = DecisionTreeRegressor(random_state=42)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      results = self.calculate_regression_scores(\"Decision Tree Regressor\", y_test, predictions)\n",
        "      results['estimator'] = model\n",
        "      return results\n",
        "\n",
        "    def regre_randomforest(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Runs Random Forest Regressor and calculates multiple performance metrics.\n",
        "      Returns:\n",
        "      - results: Dictionary of regression metrics.\n",
        "      \"\"\"\n",
        "      print(\"Starting Random Forest Regressor...\")\n",
        "      model = RandomForestRegressor(max_depth=2, random_state=42)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      results = self.calculate_regression_scores(\"Random Forest Regressor\", y_test, predictions)\n",
        "      results['estimator'] = model\n",
        "      return results\n",
        "\n",
        "    def regre_gradient_boosting(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Runs Grandient Boostsing Regressor and calculates multiple performance metrics.\n",
        "      Returns:\n",
        "      - results: Dictionary of regression metrics.\n",
        "      \"\"\"\n",
        "      print(\"Starting Grandient Boostsing Regressor...\")\n",
        "      model = GradientBoostingRegressor(random_state=42)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      results = self.calculate_regression_scores(\"Gradient Boosting Regressor\", y_test, predictions)\n",
        "      results['estimator'] = model\n",
        "      return results\n",
        "\n",
        "#------------------------Classification Models--------------------------------------------------------------\n",
        "\n",
        "    def classi_decision_tree(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Runs Decision Tree Classifier and calculates multiple performance metrics.\n",
        "      Returns:\n",
        "      - results: Dictionary with classification metrics.\n",
        "      \"\"\"\n",
        "      print(\"Starting Decision Tree Classifier...\")\n",
        "      model = DecisionTreeClassifier(random_state=0)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      results = self.calculate_classification_scores(\"Decision Tree Classifier\", y_test, predictions)\n",
        "      results['estimator'] = model\n",
        "      return results\n",
        "\n",
        "    def classi_knn(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Runs K-Nearest Neighbors Classifier and calculates multiple performance metrics.\n",
        "      Returns:\n",
        "      - results: Dictionary with classification metrics.\n",
        "      \"\"\"\n",
        "      print(\"Starting K-Nearest Neighbors Classifier...\")\n",
        "      model = KNeighborsClassifier()\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      results = self.calculate_classification_scores(\"KNN\", y_test, predictions)\n",
        "      results['estimator'] = model\n",
        "      return results\n",
        "\n",
        "    def classi_random_forest(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Runs Random Forest Classifier and calculates multiple performance metrics.\n",
        "      Returns:\n",
        "      - results: Dictionary with classification metrics.\n",
        "      \"\"\"\n",
        "      print(\"Starting Random Forest Classifier...\")\n",
        "      model = RandomForestClassifier(random_state=42)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      results = self.calculate_classification_scores(\"Random Forest Classifier\", y_test, predictions)\n",
        "      results['estimator'] = model\n",
        "      return results\n",
        "\n",
        "    def classi_adaboost(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Runs AdaBoost Classifier and calculates multiple performance metrics.\n",
        "      Returns:\n",
        "      - results: Dictionary with classification metrics.\n",
        "      \"\"\"\n",
        "      print(\"Starting AdaBoost Classifier...\")\n",
        "      model = AdaBoostClassifier(random_state=42)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      results = self.calculate_classification_scores(\"AdaBoost Classifier\", y_test, predictions)\n",
        "      results['estimator'] = model\n",
        "      return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Menu\n",
        "Calling this class allows to use all features in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Start:\n",
        "    \"\"\"\n",
        "    Class dedicated to the main controller of the program. Shows all menus that\n",
        "    the user can interact with, calling all previous classes\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Main controller, starts with no data loaded\n",
        "        \"\"\"\n",
        "        self.file_path = None\n",
        "        self.eda = None\n",
        "        self.unsupervised = None\n",
        "        self.supervised = None\n",
        "        self.dataset_loaded = False\n",
        "        \n",
        "\n",
        "    def load_dataset(self, file_name: str) -> None:\n",
        "        \"\"\"\n",
        "        Loads a dataset from a CSV file located in the datasets/ directory\n",
        "        \"\"\"\n",
        "        # If user does not provide extension csv\n",
        "        if not file_name.endswith('.csv'):\n",
        "            file_name = f\"{file_name}.csv\"\n",
        "\n",
        "        # By default is datasets/, included in the project\n",
        "        full_path = f\"datasets/{file_name}\"\n",
        "\n",
        "        if not os.path.isfile(full_path):\n",
        "            raise FileNotFoundError(f\"‚ö†Ô∏è  File not found: {full_path}\")\n",
        "        self.eda = EDA(full_path)\n",
        "        self.file_path = full_path\n",
        "        self.dataset_loaded = True\n",
        "        print(f\"‚úÖ Loaded: {full_path}\")\n",
        "    \n",
        "    def run(self) -> None:\n",
        "        \"\"\"\n",
        "        This is the first menu that the user sees. There are two main levels:\n",
        "        1) Load a dataset from a CSV file.\n",
        "        2) If a dataset is loaded, the user can choose between EDA tools or Modeling tools.\n",
        "        \"\"\"\n",
        "        plt.ioff()\n",
        "        while True:\n",
        "            # 1) Load a dataset from a CSV file\n",
        "            if not self.dataset_loaded:\n",
        "                file_name = input(\"Enter CSV file name (or 'q' to quit): \")\n",
        "                if file_name.lower() == \"q\":\n",
        "                    break\n",
        "                try:\n",
        "                    self.load_dataset(file_name)\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "                    continue  # ask again\n",
        "\n",
        "            # 2) If a dataset is loaded, the user can choose between EDA tools or Modeling tools.\n",
        "            else:\n",
        "                print(\"\\nMAIN MENU (dataset loaded)\")\n",
        "                print(\"1) EDA tools\")\n",
        "                print(\"2) Modeling tools\")\n",
        "                print(\"3) Reload dataset\")\n",
        "                print(\"0) Quit\")\n",
        "                choice = input(\"Select option: \")\n",
        "\n",
        "                if choice == \"1\":\n",
        "                    self.eda_menu()\n",
        "                elif choice == \"2\":\n",
        "                    self.model_menu()\n",
        "                elif choice == \"3\":\n",
        "                    self.dataset_loaded = False\n",
        "                elif choice == \"0\":\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Invalid input, please try again. \\n\")\n",
        "\n",
        "    def eda_menu(self):\n",
        "        \"\"\"\n",
        "        Third level menu, where the user can choose between EDA\n",
        "        tools from EDA class. The menu repeats until the user exits.\n",
        "    \n",
        "        Options:\n",
        "        - Viewing DataFrame head and data types\n",
        "        - Removing columns or null values\n",
        "        - Detecting outliers\n",
        "        - Plotting scatter, histogram, and heatmap\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            print(\"\\n------- EDA Menu -------\")\n",
        "            print(\"1) Show DataFrame head\")\n",
        "            print(\"2) Show DataFrame dtypes\")\n",
        "            print(\"3) Remove columns\")\n",
        "            print(\"4) Drop null values\")\n",
        "            print(\"5) Detect outliers\")\n",
        "            print(\"6) Plot scatter chart\")\n",
        "            print(\"7) Plot histogram\")\n",
        "            print(\"8) Plot heatmap\")\n",
        "            print(\"0) Back to main\")\n",
        "            choice = input(\"Select option: \")\n",
        "\n",
        "            if choice == \"1\":\n",
        "                print(self.eda.head_df())\n",
        "            elif choice == \"2\":\n",
        "                print(self.eda.check_data_types())\n",
        "            elif choice == \"3\":\n",
        "                column_list = input(\"Enter column names to delete (comma-separated): \").split(\",\")\n",
        "                column_list = [col.strip() for col in column_list]\n",
        "                try:\n",
        "                    self.eda.drop_irrelevant_columns(column_list)\n",
        "                    print(f\"Columns removed: {', '.join(column_list)}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error removing columns: {e}\")\n",
        "            elif choice == \"4\":\n",
        "                self.eda.drop_missing_values()\n",
        "                print(\"Null values dropped.\")\n",
        "            elif choice == \"5\":\n",
        "                print(self.eda.detect_outliers())\n",
        "            elif choice == \"6\":\n",
        "                print(\"\\n*** Available variables ***\")\n",
        "                print(self.eda.check_data_types())\n",
        "                first_var = input(\"Enter X variable name: \").strip()\n",
        "                second_var = input(\"Enter Y variable name: \").strip()\n",
        "                try:\n",
        "                    self.eda.plot_scatter(first_var, second_var)\n",
        "                except Exception as e:\n",
        "                    print(f\"Plotting error: {e}\")\n",
        "                    break\n",
        "            elif choice == \"7\":\n",
        "                print(\"\\n*** Available variables ***\")\n",
        "                print(self.eda.check_data_types())\n",
        "                histogram_var = input(\"Enter varible name: \")\n",
        "                try:\n",
        "                    self.eda.plot_histogram(histogram_var)\n",
        "                except Exception as e:\n",
        "                    print(f\"Plotting error: {e}\")\n",
        "            elif choice == \"8\":\n",
        "                self.eda.plot_heatmap()\n",
        "            elif choice == \"0\":\n",
        "                plt.close('all')\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid input, please try again. \\n\")\n",
        "\n",
        "    def model_menu(self):\n",
        "        \"\"\"\n",
        "        This is the third level menu, where the user can choose between\n",
        "        several machine learning models from Usupervised and Supervised classes.\n",
        "\n",
        "        Options:\n",
        "        - Regression models\n",
        "        - Classification models\n",
        "        - Clustering models\n",
        "        - Model serialization (after selecting any model)\n",
        "        \"\"\"\n",
        "        if self.unsupervised is None:\n",
        "            self.unsupervised = Unsupervised(self.eda)\n",
        "        if self.supervised is None:\n",
        "            self.supervised   = Supervised(self.eda)\n",
        "\n",
        "        while True:\n",
        "            print(\"\\n------- Machine Learning Models Menu -------\")\n",
        "            print(\"1) Regression\")\n",
        "            print(\"2) Classification\")\n",
        "            print(\"3) Clustering\")\n",
        "            print(\"0) Back to main\")\n",
        "            choice = input(\"Select option: \")\n",
        "\n",
        "            if choice == \"1\": # Regression\n",
        "                # Show list of columns with their data types\n",
        "                print(\"\\n*** Available variables ***\")\n",
        "                print(self.eda.check_data_types())\n",
        "\n",
        "                # Prompt user to select the target column\n",
        "                target_column = input(\"\\n Enter the name of the target column: \")\n",
        "\n",
        "                # Spliting the dataset\n",
        "                test_size = self.supervised.get_percent_data_split()\n",
        "                self.split_data = self.supervised.split_df(target_column,\n",
        "                    test_size=test_size, task_type=\"regression\")\n",
        "\n",
        "                X_train, X_test, y_train, y_test = self.split_data\n",
        "\n",
        "                # List of models evaluated\n",
        "                regre_model_group = [\n",
        "                    self.supervised.regre_lineal_simple,\n",
        "                    self.supervised.regre_regridge,\n",
        "                    self.supervised.regre_decisionTree,\n",
        "                    self.supervised.regre_randomforest,\n",
        "                    self.supervised.regre_gradient_boosting\n",
        "                ]\n",
        "\n",
        "                # Execute each model and collect results\n",
        "                regre_results = []\n",
        "                for model in regre_model_group:\n",
        "                    regre_results.append(model(X_train, X_test, y_train, y_test))\n",
        "                \n",
        "                table = PrettyTable()\n",
        "                table.field_names = [\"Model\", \"R¬≤\", \"RMSE\", \"MAE\"]\n",
        "                # Add each result as a row\n",
        "                for res in regre_results:\n",
        "                    table.add_row([\n",
        "                        res['model'],\n",
        "                        f\"{res['R2']:.4f}\",\n",
        "                        f\"{res['RMSE']:.4f}\",\n",
        "                        f\"{res['MAE']:.4f}\"\n",
        "                    ])\n",
        "                print(\"Regression Results:\")\n",
        "                print(table)\n",
        "\n",
        "                # model_list contains the model name and the model object\n",
        "                model_list = []\n",
        "                for res in regre_results:\n",
        "                    if \"estimator\" in res and res[\"estimator\"] is not None:\n",
        "                        model_list.append((res[\"model\"], res[\"estimator\"]))\n",
        "                # Section where user can serialize any evaluated model\n",
        "                self.serialize_model_menu(model_list)\n",
        "            elif choice == \"2\": # Classification\n",
        "                # Show list of columns with their data types\n",
        "                print(\"\\n*** Available variables ***\")\n",
        "                print(self.eda.check_data_types())\n",
        "\n",
        "                # Prompt user to select the target column\n",
        "                target_column = input(\"\\n Enter the name of the target column: \")\n",
        "\n",
        "                # Spliting the dataset\n",
        "                test_size = self.supervised.get_percent_data_split()\n",
        "                self.split_data = self.supervised.split_df(target_column,\n",
        "                    test_size=test_size)\n",
        "                \n",
        "                X_train, X_test, y_train, y_test = self.split_data\n",
        "\n",
        "                # List of models evaluated\n",
        "                classi_model_group = [\n",
        "                    self.supervised.classi_decision_tree,\n",
        "                    self.supervised.classi_knn,\n",
        "                    self.supervised.classi_random_forest,\n",
        "                    self.supervised.classi_adaboost\n",
        "                ]\n",
        "\n",
        "                # Execute each model and collect results\n",
        "                classi_results = []\n",
        "                for model in classi_model_group:\n",
        "                    classi_results.append(model(X_train, X_test, y_train, y_test))\n",
        "\n",
        "                table = PrettyTable()\n",
        "                table.field_names = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "                for res in classi_results:\n",
        "                    table.add_row([\n",
        "                        res['model'],\n",
        "                        f\"{res['accuracy']:.4f}\",\n",
        "                        f\"{res['precision']:.4f}\",\n",
        "                        f\"{res['recall']:.4f}\",\n",
        "                        f\"{res['f1_score']:.4f}\"\n",
        "                    ])\n",
        "                print(\"Classification Results:\")\n",
        "                print(table)\n",
        "\n",
        "                # model_list contains the model name and the model object\n",
        "                model_list = []\n",
        "                for res in classi_results:\n",
        "                    if \"estimator\" in res and res[\"estimator\"] is not None:\n",
        "                        model_list.append((res[\"model\"], res[\"estimator\"]))\n",
        "                # Section where user can serialize any evaluated model\n",
        "                self.serialize_model_menu(model_list)\n",
        "\n",
        "            elif choice == \"3\": # Clustering\n",
        "\n",
        "                # Input number of clusters\n",
        "                n_clusters = int(input(\"Enter the number of clusters (>2): \"))\n",
        "\n",
        "                # List of models evaluated\n",
        "                cluster_model_group = [\n",
        "                    lambda: self.unsupervised.kmeans(n_clusters, return_estimator=True),\n",
        "                    lambda: self.unsupervised.k_medoids(n_clusters, return_estimator=True),\n",
        "                    lambda: self.unsupervised.hac(n_clusters, return_estimator=True),\n",
        "                    lambda: self.unsupervised.umap_reduc(n_clusters, return_estimator=True)\n",
        "                ]\n",
        "\n",
        "                # Execute each model and collect results\n",
        "                cluster_results = []\n",
        "                for model_func in cluster_model_group:\n",
        "                    cluster_results.append(model_func())\n",
        "\n",
        "                table = PrettyTable()\n",
        "                table.field_names = [\"Model\", \"Silhouette Score\", \"Calinski-Harabasz\", \"Davies-Bouldin\"]\n",
        "                for res in cluster_results:\n",
        "                    metrics = res[\"metrics\"]\n",
        "                    table.add_row([\n",
        "                        res['model'],\n",
        "                        f\"{metrics['Silhouette Score']:.4f}\",\n",
        "                        f\"{metrics['Calinski-Harabasz']:.4f}\",\n",
        "                        f\"{metrics['Davies-Bouldin']:.4f}\"\n",
        "                    ])\n",
        "                print(\"Clustering Results:\")\n",
        "                print(table)\n",
        "\n",
        "                # model_list contains the model name and the model object\n",
        "                model_list = []\n",
        "                for res in cluster_results:\n",
        "                    if \"estimator\" in res and res[\"estimator\"] is not None:\n",
        "                        model_list.append((res[\"model\"], res[\"estimator\"]))\n",
        "                # Section where user can serialize any evaluated model\n",
        "                self.serialize_model_menu(model_list)\n",
        "            elif choice == \"0\":\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid input, please try again. \\n\")\n",
        "\n",
        "    # Serialization process\n",
        "    def serialize_model_menu(self, model_list):\n",
        "        \"\"\"\n",
        "        Serialize the model that user want to serialize or not.\n",
        "        model_list: list of tuples (model_name, model_object)\n",
        "\n",
        "        Returns:\n",
        "        - model_path (str): Path where the model was saved, or None if no model\n",
        "        - Data saved in serialized_models/ directory\n",
        "        \"\"\"\n",
        "\n",
        "        # Print a menu with a list of models trained to serialize one\n",
        "        print(\"\\n------- Serialization Menu -------\")\n",
        "        for idx, (model_name, _) in enumerate(model_list, start=1):\n",
        "            print(f\"{idx}. {model_name}\")\n",
        "        print(\"0. Do not serialize any model!\")\n",
        "\n",
        "        choice = input(\"Select an option: \").strip()\n",
        "        try:\n",
        "            choice_int = int(choice)\n",
        "        except ValueError:\n",
        "            print(\"Invalid input, try again.\")\n",
        "            return None\n",
        "        if choice_int == 0:\n",
        "            return None\n",
        "        if not (1 <= choice_int <= len(model_list)):\n",
        "            print(\"Option out of range. No model serialized.\")\n",
        "            return None\n",
        "\n",
        "        selected_name, selected_model = model_list[choice_int - 1]\n",
        "        # The file name will be generated with a timestamp\n",
        "        # Output: serialized_model_DATE_HOUR.joblib\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        file_name = f\"serialized_model_{timestamp}.joblib\"\n",
        "        model_path = f\"serialized_models/{file_name}\"\n",
        "        \n",
        "        # Save file\n",
        "        joblib.dump(selected_model, model_path)\n",
        "        print(f\"Model '{selected_name}' serialized to '{model_path}'\")\n",
        "        return model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Starting program\n",
        "start = Start()\n",
        "start.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml-explorer-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
